{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install openai langchain_community langchain_huggingface"
      ],
      "metadata": {
        "id": "-4_xb9y1RguP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install torch torchvision\n",
        "! pip install pandas"
      ],
      "metadata": {
        "id": "CbfxVRQyRhRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion Classification using RAG and Reasoning\n",
        "## Overview\n",
        "This notebook implements an **emotion classification** pipeline using a **Retrieval-Augmented Generation (RAG)** approach and in context learning. The goal is to classify emotions in text and assign intensity levels.\n",
        "\n",
        "## Steps in the Notebook:\n",
        "1. **Initialize OpenAI API and Setup Cache**  \n",
        "2. **Load Sentence Transformer Embeddings for Vector Storage**  \n",
        "3. **Retrieve Similar Training Examples from FAISS Vector Store**  \n",
        "4. **Construct a System Prompt for Emotion Analysis**  \n",
        "5. **Use OpenAI Model to Predict Emotions and Justifications**  \n",
        "6. **Batch Processing of CSV Files for Emotion Classification**  \n",
        "7. **Save Results and Run Interactive Chat Mode (Optional)**  \n",
        "\n",
        "## Dependencies:\n",
        "- `OpenAI` for accessing a **deepseek-chat** model  \n",
        "- `HuggingFace` embeddings for **vector search**  \n",
        "- `FAISS` for efficient **similarity search**  \n",
        "- `Pandas` for **data manipulation**  \n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "RHQ8Tuk2R6xM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoV3BDHPRaCU"
      },
      "outputs": [],
      "source": [
        "# ==============================================\n",
        "# Emotion Classification using RAG and OpenAI\n",
        "# ==============================================\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "from pathlib import Path\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import torch\n",
        "\n",
        "# --------------------------\n",
        "# 1. Initialize OpenAI Client\n",
        "# --------------------------\n",
        "# Replace with your API key (Ensure to keep it secure!)\n",
        "api_key = ''\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Setup Cache Directory\n",
        "# ------------------------------\n",
        "CACHE_DIR = Path('prompt_cache')\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Check for CUDA availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Load Sentence Transformer Embeddings\n",
        "# ------------------------------\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "    model_kwargs={'device': device}\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Caching Mechanism\n",
        "# ------------------------------\n",
        "def get_cache_key(text, system_prompt):\n",
        "    \"\"\"Generate a unique cache key for a given text and system prompt.\"\"\"\n",
        "    combined = f\"{text}||{system_prompt}\"\n",
        "    return hashlib.md5(combined.encode()).hexdigest()\n",
        "\n",
        "def get_cached_response(cache_key):\n",
        "    \"\"\"Retrieve cached response if available.\"\"\"\n",
        "    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n",
        "    if cache_file.exists():\n",
        "        with open(cache_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return None\n",
        "\n",
        "def cache_response(cache_key, response):\n",
        "    \"\"\"Store the response in cache.\"\"\"\n",
        "    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n",
        "    with open(cache_file, 'w') as f:\n",
        "        json.dump(response, f)\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Emotion Intensity Levels\n",
        "# ------------------------------\n",
        "EMOTION_LEVELS = {\n",
        "    0: \"none\",\n",
        "    1: \"low\",\n",
        "    2: \"moderate\",\n",
        "    3: \"high\",\n",
        "    # 4: \"very high\"\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Create FAISS Vector Store\n",
        "# ------------------------------\n",
        "def create_vector_store(csv_path):\n",
        "    \"\"\"Create a FAISS vector store from the training dataset.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    texts = df['text'].tolist()\n",
        "\n",
        "    # Create metadata for each text\n",
        "    metadatas = []\n",
        "    for _, row in df.iterrows():\n",
        "        emotions = {\n",
        "            'joy': row['joy'],\n",
        "            'fear': row['fear'],\n",
        "            'anger': row['anger'],\n",
        "            'sadness': row['sadness'],\n",
        "            'disgust': row['disgust'],\n",
        "            'surprise': row['surprise']\n",
        "        }\n",
        "        metadatas.append({'emotions': emotions})\n",
        "\n",
        "    # Return FAISS vector store\n",
        "    return FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
        "\n",
        "# ------------------------------\n",
        "# 7. Retrieve Similar Examples\n",
        "# ------------------------------\n",
        "def get_similar_examples(vector_store, query_text, k=5):\n",
        "    \"\"\"Retrieve k most similar examples from the vector store.\"\"\"\n",
        "    results = vector_store.similarity_search_with_score(query_text, k=k)\n",
        "\n",
        "    examples = ''\n",
        "    for i, (doc, score) in enumerate(results):\n",
        "        emotion_scores = doc.metadata['emotions']\n",
        "\n",
        "        # Convert numeric values to labels\n",
        "        emotion_descriptions = \", \".join(\n",
        "            f\"{emotion}: {EMOTION_LEVELS.get(value, 'unknown')}\"\n",
        "            for emotion, value in emotion_scores.items()\n",
        "        )\n",
        "\n",
        "        examples += f\"Input {i}: {doc.page_content}\\n\"\n",
        "        examples += f\"Output {i}: [{emotion_descriptions}]\\n\"\n",
        "\n",
        "    return examples\n",
        "\n",
        "# ------------------------------\n",
        "# 8. Construct System Prompt\n",
        "# ------------------------------\n",
        "def get_combined_prompt(examples):\n",
        "    \"\"\"Generate a single system prompt that combines reasoning, classification, and intensity analysis.\"\"\"\n",
        "    return f\"\"\"You are an emotion classification expert. Your task has two parts:\n",
        "\n",
        "1. First, analyze the text and explain why certain emotions are present or absent, and provide an intensity level (from none to high) for each emotion.\n",
        "   Consider these emotions: joy, fear, anger, sadness, disgust, surprise\n",
        "\n",
        "   Your analysis should:\n",
        "   - Provide specific evidence from the text\n",
        "   - Consider both explicit words and contextual implications\n",
        "   - Be objective and clear\n",
        "   - Assign an intensity level for each emotion: none, low, moderate, high\n",
        "\n",
        "2. Then, provide your final classification by listing all detected emotions along with their intensity levels.\n",
        "   Use only these emotions: joy, fear, anger, sadness, disgust, surprise, and the intensity levels: none, low, moderate, high.\n",
        "\n",
        "IMPORTANT:\n",
        "- The examples below are provided to help guide your reasoning. They contain insights and annotations from experts who labeled the dataset. Pay close attention to how emotions and their intensities were derived in these examples, and use this understanding to inform your own analysis.\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Explanation:\n",
        "(Your detailed analysis here, including why each emotion is assigned its specific intensity level)\n",
        "\n",
        "Final Classification:\n",
        "[emotion1: intensity1, emotion2: intensity2, ...]\n",
        "\n",
        "Here are some similar examples to help guide your analysis:\n",
        "{examples}\"\"\"\n",
        "\n",
        "# ------------------------------\n",
        "# 9. Process Emotions using RAG\n",
        "# ------------------------------\n",
        "def process_emotions(text, vector_store, system_prompt=None):\n",
        "    \"\"\"Predict emotions and reasoning using Retrieval-Augmented Generation (RAG).\"\"\"\n",
        "    try:\n",
        "        examples = get_similar_examples(vector_store, text)\n",
        "\n",
        "        if system_prompt is None:\n",
        "            system_prompt = get_combined_prompt(examples)\n",
        "\n",
        "        cache_key = get_cache_key(text, system_prompt)\n",
        "        cached_response = get_cached_response(cache_key)\n",
        "\n",
        "        if cached_response:\n",
        "            return cached_response\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"deepseek-chat\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": f\"Analyze this text and provide both the evidence analysis and final classification: {text}\"}\n",
        "            ],\n",
        "            max_tokens=1000,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        response_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Split response into reasoning and classification\n",
        "        parts = response_text.split(\"Final Classification:\")\n",
        "        if len(parts) != 2:\n",
        "            return {'emotions': {'none': 'none'}, 'reasoning': response_text}\n",
        "\n",
        "        reasoning = parts[0].replace(\"Explanation:\", \"\").strip()\n",
        "        classification = parts[1].strip()\n",
        "\n",
        "        # Extract emotions\n",
        "        pred_emotions = {'none': 'none'}\n",
        "        if '[' in classification and ']' in classification:\n",
        "            emotions_str = classification[classification.find('[')+1:classification.find(']')]\n",
        "            pred_emotions = {\n",
        "                emotion.strip().lower(): intensity.strip().lower()\n",
        "                for emotion, intensity in (item.split(':') for item in emotions_str.split(','))\n",
        "            }\n",
        "\n",
        "        result = {'emotions': pred_emotions, 'reasoning': reasoning}\n",
        "        cache_response(cache_key, result)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return {'emotions': {'none': 'none'}, 'reasoning': f\"Error: {str(e)}\"}\n",
        "\n",
        "# ------------------------------\n",
        "# 10. Batch Processing for CSV\n",
        "# ------------------------------\n",
        "def classify_emotions_batch(input_csv, output_csv, training_csv):\n",
        "    \"\"\"Process multiple texts and save results.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(input_csv)\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        print(\"Creating vector store from training data...\")\n",
        "        vector_store = create_vector_store(training_csv)\n",
        "\n",
        "        emotion_columns = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'surprise']\n",
        "        for emotion in emotion_columns:\n",
        "            df_copy[emotion] = 0\n",
        "\n",
        "        df_copy['reasoning'] = ''\n",
        "\n",
        "        intensity_map = {'none': 0, 'low': 1, 'moderate': 2, 'high': 3}\n",
        "\n",
        "        print(\"Processing texts...\")\n",
        "        for idx, row in tqdm(df_copy.iterrows(), total=len(df_copy)):\n",
        "            result = process_emotions(row['text'], vector_store)\n",
        "            pred_emotions = result.get('emotions', {'none': 'none'})\n",
        "            reasoning = result.get('reasoning', '')\n",
        "\n",
        "            for emotion, intensity in pred_emotions.items():\n",
        "                if emotion in emotion_columns:\n",
        "                    df_copy.at[idx, emotion] = intensity_map.get(intensity, 0)\n",
        "\n",
        "            df_copy.at[idx, 'reasoning'] = reasoning\n",
        "\n",
        "        df_copy.to_csv(output_csv)\n",
        "        print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 11. Run Classification\n",
        "# ------------------------------\n",
        "test_file = './track_b/dev/chn.csv'\n",
        "test_output = './track_b/dev/chn_result.csv'\n",
        "training_csv = './track_b/train/chn.csv'\n",
        "\n",
        "print(f\"Processing test file: {test_file}\")\n",
        "classify_emotions_batch(test_file, test_output, training_csv)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Emotion Classification using Reasoning\n",
        "##Overview\n",
        "This notebook implements an emotion classification pipeline using in context learning. The goal is to classify emotions in text and assign intensity levels."
      ],
      "metadata": {
        "id": "fyUkXjAWVzDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# Emotion Classification using RAG and OpenAI\n",
        "# ==============================================\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "from pathlib import Path\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import torch\n",
        "\n",
        "# --------------------------\n",
        "# 1. Initialize OpenAI Client\n",
        "# --------------------------\n",
        "# Replace with your API key (Ensure to keep it secure!)\n",
        "api_key = ''\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "# ------------------------------\n",
        "# 2. Setup Cache Directory\n",
        "# ------------------------------\n",
        "CACHE_DIR = Path('prompt_cache')\n",
        "CACHE_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Check for CUDA availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ------------------------------\n",
        "# 3. Load Sentence Transformer Embeddings\n",
        "# ------------------------------\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "    model_kwargs={'device': device}\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 4. Caching Mechanism\n",
        "# ------------------------------\n",
        "def get_cache_key(text, system_prompt):\n",
        "    \"\"\"Generate a unique cache key for a given text and system prompt.\"\"\"\n",
        "    combined = f\"{text}||{system_prompt}\"\n",
        "    return hashlib.md5(combined.encode()).hexdigest()\n",
        "\n",
        "def get_cached_response(cache_key):\n",
        "    \"\"\"Retrieve cached response if available.\"\"\"\n",
        "    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n",
        "    if cache_file.exists():\n",
        "        with open(cache_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return None\n",
        "\n",
        "def cache_response(cache_key, response):\n",
        "    \"\"\"Store the response in cache.\"\"\"\n",
        "    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n",
        "    with open(cache_file, 'w') as f:\n",
        "        json.dump(response, f)\n",
        "\n",
        "# ------------------------------\n",
        "# 5. Emotion Intensity Levels\n",
        "# ------------------------------\n",
        "EMOTION_LEVELS = {\n",
        "    0: \"none\",\n",
        "    1: \"low\",\n",
        "    2: \"moderate\",\n",
        "    3: \"high\",\n",
        "    # 4: \"very high\"\n",
        "}\n",
        "\n",
        "# ------------------------------\n",
        "# 6. Create FAISS Vector Store\n",
        "# ------------------------------\n",
        "def create_vector_store(csv_path):\n",
        "    \"\"\"Create a FAISS vector store from the training dataset.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    texts = df['text'].tolist()\n",
        "\n",
        "    # Create metadata for each text\n",
        "    metadatas = []\n",
        "    for _, row in df.iterrows():\n",
        "        emotions = {\n",
        "            'joy': row['joy'],\n",
        "            'fear': row['fear'],\n",
        "            'anger': row['anger'],\n",
        "            'sadness': row['sadness'],\n",
        "            'disgust': row['disgust'],\n",
        "            'surprise': row['surprise']\n",
        "        }\n",
        "        metadatas.append({'emotions': emotions})\n",
        "\n",
        "    # Return FAISS vector store\n",
        "    return FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
        "\n",
        "# ------------------------------\n",
        "# 7. Retrieve Similar Examples\n",
        "# ------------------------------\n",
        "def get_similar_examples(vector_store, query_text, k=5):\n",
        "    \"\"\"Retrieve k most similar examples from the vector store.\"\"\"\n",
        "    results = vector_store.similarity_search_with_score(query_text, k=k)\n",
        "\n",
        "    examples = ''\n",
        "    for i, (doc, score) in enumerate(results):\n",
        "        emotion_scores = doc.metadata['emotions']\n",
        "\n",
        "        # Convert numeric values to labels\n",
        "        emotion_descriptions = \", \".join(\n",
        "            f\"{emotion}: {EMOTION_LEVELS.get(value, 'unknown')}\"\n",
        "            for emotion, value in emotion_scores.items()\n",
        "        )\n",
        "\n",
        "        examples += f\"Input {i}: {doc.page_content}\\n\"\n",
        "        examples += f\"Output {i}: [{emotion_descriptions}]\\n\"\n",
        "\n",
        "    return examples\n",
        "\n",
        "# ------------------------------\n",
        "# 8. Construct System Prompt\n",
        "# ------------------------------\n",
        "def get_combined_prompt(examples):\n",
        "    \"\"\"Generate a single system prompt that combines reasoning, classification, and intensity analysis.\"\"\"\n",
        "    return f\"\"\"You are an emotion classification expert. Your task has two parts:\n",
        "\n",
        "1. First, analyze the text and explain why certain emotions are present or absent, and provide an intensity level (from none to high) for each emotion.\n",
        "   Consider these emotions: joy, fear, anger, sadness, disgust, surprise\n",
        "\n",
        "   Your analysis should:\n",
        "   - Provide specific evidence from the text\n",
        "   - Consider both explicit words and contextual implications\n",
        "   - Be objective and clear\n",
        "   - Assign an intensity level for each emotion: none, low, moderate, high\n",
        "\n",
        "2. Then, provide your final classification by listing all detected emotions along with their intensity levels.\n",
        "   Use only these emotions: joy, fear, anger, sadness, disgust, surprise, and the intensity levels: none, low, moderate, high.\n",
        "\n",
        "IMPORTANT:\n",
        "- The examples below are provided to help guide your reasoning. They contain insights and annotations from experts who labeled the dataset. Pay close attention to how emotions and their intensities were derived in these examples, and use this understanding to inform your own analysis.\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Explanation:\n",
        "(Your detailed analysis here, including why each emotion is assigned its specific intensity level)\n",
        "\n",
        "Final Classification:\n",
        "[emotion1: intensity1, emotion2: intensity2, ...]\n",
        "\"\"\"\n",
        "\n",
        "# ------------------------------\n",
        "# 9. Process Emotions using RAG\n",
        "# ------------------------------\n",
        "def process_emotions(text, vector_store, system_prompt=None):\n",
        "    \"\"\"Predict emotions and reasoning using Retrieval-Augmented Generation (RAG).\"\"\"\n",
        "    try:\n",
        "        examples = get_similar_examples(vector_store, text)\n",
        "\n",
        "        if system_prompt is None:\n",
        "            system_prompt = get_combined_prompt(examples)\n",
        "\n",
        "        cache_key = get_cache_key(text, system_prompt)\n",
        "        cached_response = get_cached_response(cache_key)\n",
        "\n",
        "        if cached_response:\n",
        "            return cached_response\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"deepseek-chat\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": system_prompt},\n",
        "                {\"role\": \"user\", \"content\": f\"Analyze this text and provide both the evidence analysis and final classification: {text}\"}\n",
        "            ],\n",
        "            max_tokens=1000,\n",
        "            temperature=0\n",
        "        )\n",
        "\n",
        "        response_text = response.choices[0].message.content.strip()\n",
        "\n",
        "        # Split response into reasoning and classification\n",
        "        parts = response_text.split(\"Final Classification:\")\n",
        "        if len(parts) != 2:\n",
        "            return {'emotions': {'none': 'none'}, 'reasoning': response_text}\n",
        "\n",
        "        reasoning = parts[0].replace(\"Explanation:\", \"\").strip()\n",
        "        classification = parts[1].strip()\n",
        "\n",
        "        # Extract emotions\n",
        "        pred_emotions = {'none': 'none'}\n",
        "        if '[' in classification and ']' in classification:\n",
        "            emotions_str = classification[classification.find('[')+1:classification.find(']')]\n",
        "            pred_emotions = {\n",
        "                emotion.strip().lower(): intensity.strip().lower()\n",
        "                for emotion, intensity in (item.split(':') for item in emotions_str.split(','))\n",
        "            }\n",
        "\n",
        "        result = {'emotions': pred_emotions, 'reasoning': reasoning}\n",
        "        cache_response(cache_key, result)\n",
        "        return result\n",
        "\n",
        "    except Exception as e:\n",
        "        return {'emotions': {'none': 'none'}, 'reasoning': f\"Error: {str(e)}\"}\n",
        "\n",
        "# ------------------------------\n",
        "# 10. Batch Processing for CSV\n",
        "# ------------------------------\n",
        "def classify_emotions_batch(input_csv, output_csv, training_csv):\n",
        "    \"\"\"Process multiple texts and save results.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(input_csv)\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        print(\"Creating vector store from training data...\")\n",
        "        vector_store = create_vector_store(training_csv)\n",
        "\n",
        "        emotion_columns = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'surprise']\n",
        "        for emotion in emotion_columns:\n",
        "            df_copy[emotion] = 0\n",
        "\n",
        "        df_copy['reasoning'] = ''\n",
        "\n",
        "        intensity_map = {'none': 0, 'low': 1, 'moderate': 2, 'high': 3}\n",
        "\n",
        "        print(\"Processing texts...\")\n",
        "        for idx, row in tqdm(df_copy.iterrows(), total=len(df_copy)):\n",
        "            result = process_emotions(row['text'], vector_store)\n",
        "            pred_emotions = result.get('emotions', {'none': 'none'})\n",
        "            reasoning = result.get('reasoning', '')\n",
        "\n",
        "            for emotion, intensity in pred_emotions.items():\n",
        "                if emotion in emotion_columns:\n",
        "                    df_copy.at[idx, emotion] = intensity_map.get(intensity, 0)\n",
        "\n",
        "            df_copy.at[idx, 'reasoning'] = reasoning\n",
        "\n",
        "        df_copy.to_csv(output_csv)\n",
        "        print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# ------------------------------\n",
        "# 11. Run Classification\n",
        "# ------------------------------\n",
        "test_file = './track_b/dev/chn.csv'\n",
        "test_output = './track_b/dev/chn_result.csv'\n",
        "training_csv = './track_b/train/chn.csv'\n",
        "\n",
        "print(f\"Processing test file: {test_file}\")\n",
        "classify_emotions_batch(test_file, test_output, training_csv)\n"
      ],
      "metadata": {
        "id": "HGEZilyxXitz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Emotion Classification using Prompting (Baseline)\n",
        "## Overview\n",
        "This notebook implements an **emotion classification** pipeline using prompting. It takes text as input, analyzes the emotions present, and assigns an intensity level to each detected emotion.\n"
      ],
      "metadata": {
        "id": "T25FbIJiURB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================\n",
        "# 1. Import Required Libraries\n",
        "# ==============================================\n",
        "\n",
        "import os\n",
        "import json\n",
        "import hashlib\n",
        "from openai import OpenAI\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import ast\n",
        "from pathlib import Path\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "import torch\n",
        "\n",
        "# ==============================================\n",
        "# 2. Initialize OpenAI Client\n",
        "# ==============================================\n",
        "\n",
        "# Replace with your API key (Ensure to keep it secure!)\n",
        "api_key = 'sk-3c78d047dac44ead8300502913471650'\n",
        "\n",
        "# Create an OpenAI client with DeepSeek API (alternative to GPT)\n",
        "client = OpenAI(api_key=api_key, base_url=\"https://api.deepseek.com\")\n",
        "\n",
        "# ==============================================\n",
        "# 3. Setup Cache for Storing API Responses\n",
        "# ==============================================\n",
        "\n",
        "CACHE_DIR = Path('prompt_cache')  # Define cache directory\n",
        "CACHE_DIR.mkdir(exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "# Check if GPU is available; otherwise, use CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# ==============================================\n",
        "# 4. Load Sentence Transformer Embeddings\n",
        "# ==============================================\n",
        "\n",
        "# Initialize HuggingFace transformer for sentence embeddings\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\",\n",
        "    model_kwargs={'device': device}\n",
        ")\n",
        "\n",
        "# ==============================================\n",
        "# 5. Caching Functions to Store and Retrieve API Responses\n",
        "# ==============================================\n",
        "\n",
        "def get_cache_key(text, system_prompt):\n",
        "    \"\"\"Generate a unique hash key for caching responses based on input text and system prompt.\"\"\"\n",
        "    combined = f\"{text}||{system_prompt}\"\n",
        "    return hashlib.md5(combined.encode()).hexdigest()\n",
        "\n",
        "def get_cached_response(cache_key):\n",
        "    \"\"\"Retrieve cached response if available to avoid redundant API calls.\"\"\"\n",
        "    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n",
        "    if cache_file.exists():\n",
        "        with open(cache_file, 'r') as f:\n",
        "            return json.load(f)\n",
        "    return None  # Return None if no cached response exists\n",
        "\n",
        "def cache_response(cache_key, response):\n",
        "    \"\"\"Store API responses in a JSON cache file to reduce redundant calls.\"\"\"\n",
        "    cache_file = CACHE_DIR / f\"{cache_key}.json\"\n",
        "    with open(cache_file, 'w') as f:\n",
        "        json.dump(response, f)\n",
        "\n",
        "# ==============================================\n",
        "# 6. Define Emotion Intensity Levels\n",
        "# ==============================================\n",
        "\n",
        "EMOTION_LEVELS = {\n",
        "    0: \"none\",\n",
        "    1: \"low\",\n",
        "    2: \"moderate\",\n",
        "    3: \"high\",\n",
        "    # 4: \"very high\"  # Commented out if not in use\n",
        "}\n",
        "\n",
        "# ==============================================\n",
        "# 7. Create a FAISS Vector Store from CSV Data\n",
        "# ==============================================\n",
        "\n",
        "def create_vector_store(csv_path):\n",
        "    \"\"\"Create a FAISS vector store from a dataset of text samples.\"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    texts = df['text'].tolist()  # Extract text column\n",
        "\n",
        "    # Generate metadata (emotion labels) for each text sample\n",
        "    metadatas = []\n",
        "    for _, row in df.iterrows():\n",
        "        emotions = {\n",
        "            'joy': row['joy'],\n",
        "            'fear': row['fear'],\n",
        "            'anger': row['anger'],\n",
        "            'sadness': row['sadness'],\n",
        "            'disgust': row['disgust'],\n",
        "            'surprise': row['surprise']\n",
        "        }\n",
        "        metadatas.append({'emotions': emotions})\n",
        "\n",
        "    # Return FAISS vector store with text and metadata\n",
        "    return FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
        "\n",
        "# ==============================================\n",
        "# 8. Construct System Prompt for Emotion Analysis\n",
        "# ==============================================\n",
        "\n",
        "def get_combined_prompt():\n",
        "    \"\"\"Generate a single system prompt that defines the classification task.\"\"\"\n",
        "    return \"\"\"You are an emotion classification expert. Your task is to classify the emotions present in the given text and assign an intensity level (from none to high) for each emotion.\n",
        "\n",
        "Consider these emotions: joy, fear, anger, sadness, disgust, surprise.\n",
        "\n",
        "Assign an intensity level for each emotion from the following options: none, low, moderate, high.\n",
        "\n",
        "Format your response EXACTLY as follows:\n",
        "\n",
        "Final Classification:\n",
        "[joy: intensity, fear: intensity, anger: intensity, sadness: intensity, disgust: intensity, surprise: intensity]\n",
        "\"\"\"\n",
        "\n",
        "# ==============================================\n",
        "# 9. Batch Processing for Emotion Classification\n",
        "# ==============================================\n",
        "\n",
        "def classify_emotions_batch(input_csv, output_csv, training_csv):\n",
        "    \"\"\"Process multiple texts and save results.\"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(input_csv)\n",
        "        df_copy = df.copy()\n",
        "\n",
        "        print(\"Creating vector store from training data...\")\n",
        "        vector_store = create_vector_store(training_csv)\n",
        "\n",
        "        emotion_columns = ['joy', 'fear', 'anger', 'sadness', 'disgust', 'surprise']\n",
        "        for emotion in emotion_columns:\n",
        "            df_copy[emotion] = 0  # Initialize emotion columns\n",
        "\n",
        "        # Map intensities to numeric values\n",
        "        intensity_map = {'none': 0, 'low': 1, 'moderate': 2, 'high': 3}\n",
        "\n",
        "        print(\"Processing texts...\")\n",
        "        for idx, row in tqdm(df_copy.iterrows(), total=len(df_copy)):\n",
        "            try:\n",
        "                text = row['text']\n",
        "\n",
        "                # Generate cache key to avoid redundant API calls\n",
        "                cache_key = get_cache_key(text, \"emotion_analysis\")\n",
        "                cached_response = get_cached_response(cache_key)\n",
        "\n",
        "                if cached_response:\n",
        "                    pred_emotions = cached_response\n",
        "                else:\n",
        "                    response = client.chat.completions.create(\n",
        "                        model=\"deepseek-chat\",\n",
        "                        messages=[\n",
        "                            {\"role\": \"system\", \"content\": get_combined_prompt()},\n",
        "                            {\"role\": \"user\", \"content\": f\"Classify emotions in: {text}\"}\n",
        "                        ],\n",
        "                        max_tokens=1000,\n",
        "                        temperature=0\n",
        "                    )\n",
        "\n",
        "                    response_text = response.choices[0].message.content.strip()\n",
        "                    pred_emotions = {emotion.strip().lower(): \"low\" for emotion in response_text.split(',')}\n",
        "                    cache_response(cache_key, pred_emotions)\n",
        "\n",
        "                # Update emotion intensity columns with numeric values\n",
        "                for emotion, intensity in pred_emotions.items():\n",
        "                    if emotion in emotion_columns:\n",
        "                        df_copy.at[idx, emotion] = intensity_map.get(intensity, 0)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row {idx}: {e}\")\n",
        "                for emotion in emotion_columns:\n",
        "                    df_copy.at[idx, emotion] = 0  # Default to 0 for all emotions\n",
        "\n",
        "        df_copy.to_csv(output_csv)\n",
        "        print(f\"Results saved to {output_csv}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# ==============================================\n",
        "# 10. Run Emotion Classification on Test Data\n",
        "# ==============================================\n",
        "\n",
        "test_file = './track_b/dev/esp.csv'\n",
        "test_output = './track_b/dev/esp_result_without_exm.csv'\n",
        "training_csv = './track_b/train/esp.csv'\n",
        "\n",
        "print(f\"Processing test file: {test_file}\")\n",
        "classify_emotions_batch(test_file, test_output, training_csv)\n"
      ],
      "metadata": {
        "id": "wUykwvjfS2ar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}